import streamlit as st
from openai import OpenAI
import os
import numpy as np

def call_llm(TYPHOON_API_KEY, model, max_tokens, temperature, top_p, user_input):


    client = OpenAI(
        api_key=TYPHOON_API_KEY,
        base_url="https://api.opentyphoon.ai/v1",
    )
    try:

        stream = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "system",
                    "content": """
                    ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏£‡∏±‡∏ö‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏°‡∏ß 
                    <‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠>
                        1.‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≠‡∏¢‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏à‡πÄ‡∏à‡πâ‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
                        
                    <‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏ô‡∏¥‡∏™‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì>
                        1.‡∏Ñ‡∏∏‡∏ì‡∏£‡∏±‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏¥‡∏™‡∏£‡∏∞‡πÅ‡∏•‡∏∞‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏ä‡∏≠‡∏ö‡∏ó‡∏≥‡∏™‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ
                        2.‡∏ï‡∏≤‡∏°‡πÉ‡∏à‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á
                        3.‡πÑ‡∏°‡πà‡∏Ñ‡πà‡∏≠‡∏¢‡∏ä‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á
                        4.‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡∏ô‡∏¥‡∏™‡∏±‡∏¢‡∏Ç‡∏µ‡πâ‡∏≠‡πâ‡∏≠‡∏ô‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏¢‡∏¥‡πà‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÑ‡∏ß‡πâ‡πÉ‡∏à
                        5.‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏±‡∏ï‡∏ß‡πå‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
                    """,
                
                },
                {
                    "role": "user",
                    "content": user_input,
                }
            ],
            max_tokens=max_tokens,
            temperature=temperature,
            top_p=top_p,
            stream=True,
        )
    except:
        return '<API_KEY_ERROR>'

    else:
        respond=[]
        for chunk in stream:
            if hasattr(chunk, 'choices') and len(chunk.choices) > 0:
                choice = chunk.choices[0]
                if hasattr(choice, 'delta') and hasattr(choice.delta, 'content'):
                    if choice.delta.content is not None:
                        respond.append(choice.delta.content)

        return "".join(respond)

def main():
    st.title(":orange[Back To Hometown DEMO]")
    st.markdown(':blue[‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö] :violet[‡∏™‡∏±‡∏ï‡∏ß‡πå‡πÄ‡∏•‡∏µ‡πâ‡∏¢‡∏á] :green[Ai] :red[‡∏™‡∏∏‡∏î‡∏ô‡πà‡∏≤‡∏£‡∏±‡∏Å]:orange[‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Ñ‡∏≠‡∏¢‡∏ñ‡∏≤‡∏°‡∏Æ‡∏µ‡∏•‡πÉ‡∏à‡πÄ‡∏£‡∏≤]')
    st.caption("Powered by Typhoon SCB10x")
    
    with st.sidebar:
        
        a, b, c, d = st.columns(4)
        with b:
            st.image('app_logo.png', width=125)
                
        st.title("Config")
        st.markdown('Generate key form https://opentyphoon.ai/')
        
        if "typhoon_api_key" not in st.session_state:
            st.session_state["typhoon_api_key"] = ""
    
        # Input fields
        typhoon_api_key = st.text_input(
            label='TYPHOON API KEY', 
            placeholder='Place key here', 
            value=st.session_state.get('typhoon_api_key', '')
        )
        
        model = st.selectbox(
            label="Model", 
            options=( "typhoon-instruct", "typhoon-v1.5x-70b-instruct"),
            index=st.session_state.get('model_index', 0)
        )
        
        max_token = st.slider(
            label='Max Token', 
            min_value=50, 
            max_value=512, 
            step=10, 
            value=st.session_state.get('max_token', 300)
        )
        
        temperature = st.slider(
            label='Temperature', 
            min_value=0.0, 
            max_value=1.0, 
            step=0.05, 
            value=st.session_state.get('temperature', 0.6)
        )
        
        top_p = st.slider(
            label='Top P', 
            min_value=0.0, 
            max_value=1.0, 
            step=0.05, 
            value=st.session_state.get('top_p', 0.95)
        )

        # Save button
        if st.button('Save Config'):
            st.session_state['typhoon_api_key'] = typhoon_api_key
            st.session_state['model'] = model
            st.session_state['max_token'] = max_token
            st.session_state['temperature'] = temperature
            st.session_state['top_p'] = top_p
            st.success("Configuration saved!")

    with st.chat_message("assistant", avatar='üò∏'):
        st.write("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡πÄ‡∏°‡∏µ‡πä‡∏¢‡∏ß‡∏ß‡∏ß‡∏ß‡∏ß")
                
    prompt = st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ!!")
            
    if 'conversation' not in st.session_state:
        st.session_state['conversation'] = []
        
    if prompt:
        st.session_state['conversation'].append({"role": "user", "content": prompt})

        conversation_history = "\n".join([f"{msg['content']}" for msg in st.session_state['conversation']])
        response = call_llm(st.session_state['typhoon_api_key'], st.session_state['model'], st.session_state['max_token'], st.session_state['temperature'], st.session_state['top_p'], conversation_history)

        st.session_state['conversation'].append({"role": "assistant", "content": response})

        for msg in st.session_state['conversation']:
            with st.chat_message(msg['role']):
                st.write(msg['content'])
                
if __name__ == "__main__":
    main()